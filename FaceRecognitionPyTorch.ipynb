{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123127f3-1158-482e-8ae4-8549cda5af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Hyperparameters and paths\n",
    "train_dataset_path = \" \"\n",
    "val_dataset_path = \" \"\n",
    "batch_size = 8\n",
    "learning_rate = 0.0005\n",
    "num_epochs = 150\n",
    "margin = 2.0\n",
    "\n",
    "# Plotting data\n",
    "def show_plot(iteration, train_loss, val_loss):\n",
    "    plt.plot(iteration, train_loss, label='Training Loss')\n",
    "    plt.plot(iteration, val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def show_test_plot(iteration, test_data, label):\n",
    "    plt.plot(iteration, test_data, label='Test ' + label)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel(label)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "class SiameseNetworkDataset(Dataset):\n",
    "    def __init__(self, imageFolderDataset, transform=None):\n",
    "        self.imageFolderDataset = imageFolderDataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "\n",
    "        # We need to approximately 50% of images to be in the same class\n",
    "        should_get_same_class = random.randint(0, 1)\n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                # Look until the same class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "                if img0_tuple[1] == img1_tuple[1]:\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                # Look until a different class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "                if img0_tuple[1] != img1_tuple[1]:\n",
    "                    break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "\n",
    "        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)\n",
    "\n",
    "# Resize the images and transform to tensors\n",
    "transformation = transforms.Compose([transforms.Resize((100, 100)),\n",
    "                                     transforms.ToTensor()\n",
    "                                    ])\n",
    "\n",
    "# Load the training dataset\n",
    "train_folder_dataset = datasets.ImageFolder(root=train_dataset_path)\n",
    "val_folder_dataset = datasets.ImageFolder(root=val_dataset_path)\n",
    "\n",
    "# Initialize the network\n",
    "train_siamese_dataset = SiameseNetworkDataset(imageFolderDataset=train_folder_dataset,\n",
    "                                              transform=transformation)\n",
    "val_siamese_dataset = SiameseNetworkDataset(imageFolderDataset=val_folder_dataset,\n",
    "                                            transform=transformation)\n",
    "\n",
    "# Load the training and validation datasets\n",
    "train_dataloader = DataLoader(train_siamese_dataset, shuffle=True, num_workers=0, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_siamese_dataset, shuffle=True, num_workers=0, batch_size=batch_size)\n",
    "\n",
    "# Create the Siamese Neural Network\n",
    "class SiameseNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Setting up the Fully Connected Layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(384, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        # This function will be called for both images\n",
    "        # Its output is used to determine the similarity\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # In this function we pass in both images and obtain both vectors\n",
    "        # which are returned\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "\n",
    "        return output1, output2\n",
    "\n",
    "# Define the Contrastive Loss Function\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # Calculate the Euclidean distance and calculate the contrastive loss\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)\n",
    "\n",
    "        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "        return loss_contrastive\n",
    "\n",
    "model = SiameseNetwork().cuda()\n",
    "criterion = ContrastiveLoss(margin=margin)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "counter = []\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "auc_roc_score_history = []\n",
    "iteration_number = 0\n",
    "\n",
    "# Iterate through the epochs\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss_epoch = 0\n",
    "    val_loss_epoch = 0\n",
    "    auc_roc_score_epoch = 0\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    for i, (img0, img1, label) in enumerate(train_dataloader, 0):\n",
    "        # Send the images and labels to CUDA\n",
    "        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass in the two images into the network and obtain two outputs\n",
    "        output1, output2 = model(img0, img1)\n",
    "\n",
    "        # Pass the outputs of the networks and label into the loss function\n",
    "        loss_contrastive = criterion(output1, output2, label)\n",
    "\n",
    "        # Calculate the backpropagation\n",
    "        loss_contrastive.backward()\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_epoch += loss_contrastive.item()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (img0, img1, label) in enumerate(val_dataloader, 0):\n",
    "            # Send the images and labels to CUDA\n",
    "            img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "\n",
    "            # Pass in the two images into the network and obtain two outputs\n",
    "            output1, output2 = model(img0, img1)\n",
    "\n",
    "            # Pass the outputs of the networks and label into the loss function\n",
    "            loss_contrastive = criterion(output1, output2, label)\n",
    "\n",
    "            val_loss_epoch += loss_contrastive.item()\n",
    "\n",
    "    # Average losses\n",
    "    train_loss_epoch /= len(train_dataloader)\n",
    "    val_loss_epoch /= len(val_dataloader)\n",
    "\n",
    "    # Calculate AUC-ROC for validation data\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, (img0, img1, label) in enumerate(val_dataloader, 0):\n",
    "            # Send the images and labels to CUDA\n",
    "            img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "\n",
    "            # Pass in the two images into the network and obtain two outputs\n",
    "            output1, output2 = model(img0, img1)\n",
    "\n",
    "            # Calculate AUC-ROC\n",
    "            euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "            predictions.extend((euclidean_distance > 1.0).float().cpu().numpy())\n",
    "            true_labels.extend(label.cpu().numpy())\n",
    "\n",
    "    auc_roc = roc_auc_score(true_labels, predictions)\n",
    "\n",
    "    print(f\"Epoch number {epoch}\\n Train loss {train_loss_epoch}\\n Validation loss {val_loss_epoch}\\n AUC-ROC {auc_roc}\\n\")\n",
    "\n",
    "    counter.append(iteration_number)\n",
    "    train_loss_history.append(train_loss_epoch)\n",
    "    val_loss_history.append(val_loss_epoch)\n",
    "    auc_roc_score_history.append(auc_roc)\n",
    "    iteration_number += 1\n",
    "\n",
    "show_plot(counter, train_loss_history, val_loss_history)\n",
    "show_test_plot(counter, auc_roc_score_history, 'AUC-ROC')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
